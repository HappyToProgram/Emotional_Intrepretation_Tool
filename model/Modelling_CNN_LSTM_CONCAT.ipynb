{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fafe86bf",
   "metadata": {},
   "source": [
    "# Modelling CONCAT\n",
    "- This notebook uses the data obtained from Pre-Processing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2674903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import librosa\n",
    "import multiprocessing as mp\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52ceb613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Seed for Reproducibility\n",
    "tf.keras.utils.set_random_seed(442)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57c25fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-28 21:32:53.379234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-28 21:32:53.384133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-28 21:32:53.384240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "# GPU Usage\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "# Set memory growth\n",
    "tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44e0892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeldict = {\n",
    "    'Sadness': 0,\n",
    "    'Excited': 1,\n",
    "    'Happiness': 2,\n",
    "    'Anger' : 3,\n",
    "    'Frustration' : 4,\n",
    "    'Other' : 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccf9f9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(label):\n",
    "    one_hot = np.zeros(6)\n",
    "    one_hot[labeldict[label]] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d30a007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_list(listOfLabels):\n",
    "    finalList = []\n",
    "    for label in listOfLabels:\n",
    "        finalList.append(one_hot_encode(label))\n",
    "    return np.array(finalList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "904a4ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_STFT_and_label(path):\n",
    "    emotion = re.match('.*/DATA/([a-zA-Z]+)/.*', path).groups()[0]\n",
    "    data, _ = librosa.load(path, sr=44100)\n",
    "    STFT = np.abs(librosa.stft(data))\n",
    "    return STFT, emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "822e9899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(pathList): # Returns a list of x (batch_size, timesteps, feature), y (one_hot_encoded)\n",
    "    with mp.Pool() as p:\n",
    "        results = p.map(get_STFT_and_label, pathList)\n",
    "    # Preprocess x:\n",
    "    x = [item[0] for item in results]\n",
    "    # Flatten\n",
    "    x = [item for sublist in x for item in sublist]\n",
    "    # Zero-padding:\n",
    "    x = keras.preprocessing.sequence.pad_sequences(x, padding=\"post\", maxlen=1497, dtype = np.float32) # maxlen is after discovering the whole training data\n",
    "    # Reshaping so that the order is not messed up\n",
    "    x = x.reshape(-1, 1025, 1497)\n",
    "    # Transposing so that we have timesteps in dim 1\n",
    "    x = x.transpose((0, 2, 1))\n",
    "    # Preprocess y:\n",
    "    y = [item[1] for item in results]\n",
    "    # one_hot_encode\n",
    "    y = one_hot_encode_list(y)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8a5000",
   "metadata": {},
   "source": [
    "# Loading data: \n",
    "- We will load the data per predefined batch size, this is to reduce the memory used for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5fbf7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_paths.pkl', 'rb') as f:\n",
    "    train_paths = pickle.load(f)\n",
    "with open('test_paths.pkl', 'rb') as f:\n",
    "    test_paths = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "841dfc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make batches of the pathList:\n",
    "def create_batches(pathList, batch_size):\n",
    "    ansList = [] # To store the final batched paths\n",
    "    tempList = [] # Temporary list\n",
    "    count = 0\n",
    "    while count < len(pathList):\n",
    "        tempList.append(pathList[count]) # Append the path\n",
    "        count += 1\n",
    "        if (count % batch_size) == 0: # if count is a multiple of batch_size\n",
    "            ansList.append(tempList)\n",
    "            tempList = []\n",
    "    if len(tempList) != 0: # If tempList is not empty\n",
    "        ansList.append(tempList) # Append the remaining values\n",
    "    return ansList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28921b58",
   "metadata": {},
   "source": [
    "# Modelling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "920ba4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-28 21:32:57.529359: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-28 21:32:57.530194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-28 21:32:57.530343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-28 21:32:57.530404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-28 21:32:57.813765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-28 21:32:57.813897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-28 21:32:57.813961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-28 21:32:57.814040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6108 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Keras API:\n",
    "inp = layers.Input(shape=(1497, 1025)) # Let's make to fixed so that we could use CNN more efficiently\n",
    "\n",
    "# CNN part:\n",
    "\n",
    "# For 3D CNN we need to make it in the shape of (batch, height, width, channel)\n",
    "x = tf.expand_dims(inp, 3)\n",
    "\n",
    "# first:\n",
    "x = layers.Conv2D(16, kernel_size=(12,8), padding='same', strides=8)(x)\n",
    "x = layers.LeakyReLU()(x) # Activation is leaky relu and not relu (See Dying Relu problem that leads to overfitting)\n",
    "x = layers.MaxPool2D(pool_size=(2,2), padding='same')(x)\n",
    "\n",
    "# second:\n",
    "x = layers.Conv2D(32, kernel_size=(8,6), padding='same', strides=6)(x)\n",
    "x = layers.LeakyReLU()(x) # Activation is leaky relu \n",
    "x = layers.MaxPool2D(pool_size=(2,2), padding='same')(x)\n",
    "\n",
    "# Third\n",
    "x = layers.Conv2D(32, kernel_size=(3,3), padding='same', strides=3)(x)\n",
    "x = layers.LeakyReLU()(x) # Activation is leaky relu\n",
    "x = layers.MaxPool2D(pool_size=(2,2), padding='same')(x)\n",
    "\n",
    "# Flattten:\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "# LSTM:\n",
    "x_LSTM = layers.Masking(mask_value=0.0)(inp)\n",
    "total_seq1, final_hidden_state1, final_cell_state1 = layers.LSTM(128, return_state=True, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)(x_LSTM)\n",
    "total_seq2, final_hidden_state2, final_cell_state2 = layers.LSTM(128, return_state=True, dropout=0.3, recurrent_dropout=0.3)(total_seq1, initial_state=[final_hidden_state1, final_cell_state1])\n",
    "\n",
    "x = layers.concatenate([x, final_hidden_state2, final_cell_state2], axis = 1)\n",
    "\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "x = layers.Dense(6, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inp, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3908fe4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1497, 1025)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 1497, 1025,   0           ['input_1[0][0]']                \n",
      "                                1)                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 188, 129, 16  1552        ['tf.expand_dims[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 188, 129, 16  0           ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 94, 65, 16)   0           ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 16, 11, 32)   24608       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 16, 11, 32)   0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 8, 6, 32)    0           ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 3, 2, 32)     9248        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 3, 2, 32)     0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " masking (Masking)              (None, 1497, 1025)   0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 2, 1, 32)    0           ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 1497, 128),  590848      ['masking[0][0]']                \n",
      "                                 (None, 128),                                                     \n",
      "                                 (None, 128)]                                                     \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 64)           0           ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 128),        131584      ['lstm[0][0]',                   \n",
      "                                 (None, 128),                     'lstm[0][1]',                   \n",
      "                                 (None, 128)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 320)          0           ['flatten[0][0]',                \n",
      "                                                                  'lstm_1[0][1]',                 \n",
      "                                                                  'lstm_1[0][2]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          41088       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           8256        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 64)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 6)            390         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 807,574\n",
      "Trainable params: 807,574\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b122fa",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28347024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch_size is 32, epochs = 30\n",
    "batch_size = 32\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87f92c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer is Stochastic Gradient Descent\n",
    "# Loss function is Categorical Crossentropy\n",
    "optimizer = keras.optimizers.Adam() #amsgrad=True\n",
    "loss_fn = keras.losses.CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc25bc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_batch = create_batches(train_paths, batch_size=batch_size)\n",
    "validation_batch = create_batches(test_paths, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3369e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics:\n",
    "train_metrics = tf.keras.metrics.CategoricalAccuracy()\n",
    "validation_metrics = tf.keras.metrics.CategoricalAccuracy()\n",
    "train_loss = tf.keras.metrics.CategoricalCrossentropy()\n",
    "validation_loss = tf.keras.metrics.CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "538ba3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list to store epoch results:\n",
    "epoch_accuracy_train = []\n",
    "epoch_accuracy_val = []\n",
    "epoch_loss_train = []\n",
    "epoch_loss_val = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f3c97fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To speed up, use graph execution\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x, training = True)\n",
    "        loss = loss_fn(y, y_pred)\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    # Update training accuracy\n",
    "    train_metrics.update_state(y, y_pred)\n",
    "    # Update training loss:\n",
    "    train_loss.update_state(y, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a850e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def valid_step(x, y):\n",
    "    y_val_pred = model(x, training=False)\n",
    "    # Update metrics for validation\n",
    "    validation_metrics.update_state(y, y_val_pred)\n",
    "    validation_loss.update_state(y, y_val_pred)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1971ed86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-28 21:33:12.628390: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8201\n",
      "2022-05-28 21:33:14.161591: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-05-28 21:33:16.810666: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 814.81MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-05-28 21:33:16.814028: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 813.85MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-05-28 21:33:16.814065: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 813.85MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-05-28 21:33:16.829706: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 814.04MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-05-28 21:33:16.829745: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 813.85MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 10: 1.7611\n",
      "Seen so far: 352 samples\n",
      "Training loss (for one batch) at step 20: 1.6892\n",
      "Seen so far: 672 samples\n",
      "Training loss (for one batch) at step 30: 1.7965\n",
      "Seen so far: 992 samples\n",
      "Training loss (for one batch) at step 40: 2.0128\n",
      "Seen so far: 1312 samples\n",
      "Training loss (for one batch) at step 50: 1.6516\n",
      "Seen so far: 1632 samples\n",
      "Training loss (for one batch) at step 60: 1.7462\n",
      "Seen so far: 1952 samples\n",
      "Training loss (for one batch) at step 70: 1.7188\n",
      "Seen so far: 2272 samples\n",
      "Training loss (for one batch) at step 80: 1.6877\n",
      "Seen so far: 2592 samples\n",
      "Training loss (for one batch) at step 90: 1.6493\n",
      "Seen so far: 2912 samples\n",
      "Training loss (for one batch) at step 100: 1.8844\n",
      "Seen so far: 3232 samples\n",
      "Training loss (for one batch) at step 110: 1.5474\n",
      "Seen so far: 3552 samples\n",
      "Training loss (for one batch) at step 120: 1.6357\n",
      "Seen so far: 3872 samples\n",
      "Training loss (for one batch) at step 130: 1.6396\n",
      "Seen so far: 4192 samples\n",
      "Training loss (for one batch) at step 140: 1.6883\n",
      "Seen so far: 4512 samples\n",
      "Training acc over epoch: 0.2683\n",
      "Training loss over epoch: 1.7079\n",
      "Validation acc: 0.2950\n",
      "Validation loss: 1.6831\n",
      "Time taken: 869.71s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 10: 1.5774\n",
      "Seen so far: 352 samples\n",
      "Training loss (for one batch) at step 20: 1.5382\n",
      "Seen so far: 672 samples\n",
      "Training loss (for one batch) at step 30: 1.4785\n",
      "Seen so far: 992 samples\n",
      "Training loss (for one batch) at step 40: 1.5724\n",
      "Seen so far: 1312 samples\n",
      "Training loss (for one batch) at step 50: 1.4695\n",
      "Seen so far: 1632 samples\n",
      "Training loss (for one batch) at step 60: 1.6176\n",
      "Seen so far: 1952 samples\n",
      "Training loss (for one batch) at step 70: 1.3356\n",
      "Seen so far: 2272 samples\n",
      "Training loss (for one batch) at step 80: 1.3874\n",
      "Seen so far: 2592 samples\n",
      "Training loss (for one batch) at step 90: 1.6162\n",
      "Seen so far: 2912 samples\n",
      "Training loss (for one batch) at step 100: 1.5733\n",
      "Seen so far: 3232 samples\n",
      "Training loss (for one batch) at step 110: 1.4138\n",
      "Seen so far: 3552 samples\n",
      "Training loss (for one batch) at step 120: 1.5621\n",
      "Seen so far: 3872 samples\n",
      "Training loss (for one batch) at step 130: 1.5076\n",
      "Seen so far: 4192 samples\n",
      "Training loss (for one batch) at step 140: 1.5350\n",
      "Seen so far: 4512 samples\n",
      "Training acc over epoch: 0.3458\n",
      "Training loss over epoch: 1.5588\n",
      "Validation acc: 0.3783\n",
      "Validation loss: 1.4601\n",
      "Time taken: 812.06s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 10: 1.5153\n",
      "Seen so far: 352 samples\n",
      "Training loss (for one batch) at step 20: 1.4251\n",
      "Seen so far: 672 samples\n",
      "Training loss (for one batch) at step 30: 1.5568\n",
      "Seen so far: 992 samples\n",
      "Training loss (for one batch) at step 40: 1.5583\n",
      "Seen so far: 1312 samples\n",
      "Training loss (for one batch) at step 50: 1.5203\n",
      "Seen so far: 1632 samples\n",
      "Training loss (for one batch) at step 60: 1.7959\n",
      "Seen so far: 1952 samples\n",
      "Training loss (for one batch) at step 70: 1.5070\n",
      "Seen so far: 2272 samples\n",
      "Training loss (for one batch) at step 80: 1.7099\n",
      "Seen so far: 2592 samples\n",
      "Training loss (for one batch) at step 90: 1.4250\n",
      "Seen so far: 2912 samples\n",
      "Training loss (for one batch) at step 100: 1.4972\n",
      "Seen so far: 3232 samples\n",
      "Training loss (for one batch) at step 110: 1.5578\n",
      "Seen so far: 3552 samples\n",
      "Training loss (for one batch) at step 120: 1.5880\n",
      "Seen so far: 3872 samples\n",
      "Training loss (for one batch) at step 130: 1.5280\n",
      "Seen so far: 4192 samples\n",
      "Training loss (for one batch) at step 140: 1.5366\n",
      "Seen so far: 4512 samples\n",
      "Training acc over epoch: 0.3812\n",
      "Training loss over epoch: 1.4738\n",
      "Validation acc: 0.3933\n",
      "Validation loss: 1.4579\n",
      "Time taken: 830.32s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 10: 1.6007\n",
      "Seen so far: 352 samples\n",
      "Training loss (for one batch) at step 20: 1.4927\n",
      "Seen so far: 672 samples\n",
      "Training loss (for one batch) at step 30: 1.5758\n",
      "Seen so far: 992 samples\n",
      "Training loss (for one batch) at step 40: 1.1893\n",
      "Seen so far: 1312 samples\n",
      "Training loss (for one batch) at step 50: 1.1723\n",
      "Seen so far: 1632 samples\n",
      "Training loss (for one batch) at step 60: 1.3120\n",
      "Seen so far: 1952 samples\n",
      "Training loss (for one batch) at step 70: 1.4084\n",
      "Seen so far: 2272 samples\n",
      "Training loss (for one batch) at step 80: 1.4498\n",
      "Seen so far: 2592 samples\n",
      "Training loss (for one batch) at step 90: 1.2678\n",
      "Seen so far: 2912 samples\n",
      "Training loss (for one batch) at step 100: 1.3514\n",
      "Seen so far: 3232 samples\n",
      "Training loss (for one batch) at step 110: 1.4805\n",
      "Seen so far: 3552 samples\n",
      "Training loss (for one batch) at step 120: 1.5057\n",
      "Seen so far: 3872 samples\n",
      "Training loss (for one batch) at step 130: 1.4387\n",
      "Seen so far: 4192 samples\n",
      "Training loss (for one batch) at step 140: 1.5231\n",
      "Seen so far: 4512 samples\n",
      "Training acc over epoch: 0.3944\n",
      "Training loss over epoch: 1.4240\n",
      "Validation acc: 0.3650\n",
      "Validation loss: 1.4761\n",
      "Time taken: 838.42s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 10: 1.4344\n",
      "Seen so far: 352 samples\n",
      "Training loss (for one batch) at step 20: 1.4188\n",
      "Seen so far: 672 samples\n",
      "Training loss (for one batch) at step 30: 1.2403\n",
      "Seen so far: 992 samples\n",
      "Training loss (for one batch) at step 40: 1.3943\n",
      "Seen so far: 1312 samples\n",
      "Training loss (for one batch) at step 50: 1.3481\n",
      "Seen so far: 1632 samples\n",
      "Training loss (for one batch) at step 60: 1.3833\n",
      "Seen so far: 1952 samples\n",
      "Training loss (for one batch) at step 70: 1.4764\n",
      "Seen so far: 2272 samples\n",
      "Training loss (for one batch) at step 80: 1.5997\n",
      "Seen so far: 2592 samples\n",
      "Training loss (for one batch) at step 90: 1.3993\n",
      "Seen so far: 2912 samples\n",
      "Training loss (for one batch) at step 100: 1.1551\n",
      "Seen so far: 3232 samples\n",
      "Training loss (for one batch) at step 110: 1.4843\n",
      "Seen so far: 3552 samples\n",
      "Training loss (for one batch) at step 120: 1.5021\n",
      "Seen so far: 3872 samples\n",
      "Training loss (for one batch) at step 130: 1.3440\n",
      "Seen so far: 4192 samples\n",
      "Training loss (for one batch) at step 140: 1.5178\n",
      "Seen so far: 4512 samples\n",
      "Training acc over epoch: 0.4100\n",
      "Training loss over epoch: 1.3817\n",
      "Validation acc: 0.3758\n",
      "Validation loss: 1.4636\n",
      "Time taken: 865.04s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 10: 1.5485\n",
      "Seen so far: 352 samples\n",
      "Training loss (for one batch) at step 20: 1.3798\n",
      "Seen so far: 672 samples\n",
      "Training loss (for one batch) at step 30: 1.2082\n",
      "Seen so far: 992 samples\n",
      "Training loss (for one batch) at step 40: 1.2594\n",
      "Seen so far: 1312 samples\n",
      "Training loss (for one batch) at step 50: 1.3910\n",
      "Seen so far: 1632 samples\n",
      "Training loss (for one batch) at step 60: 1.3492\n",
      "Seen so far: 1952 samples\n",
      "Training loss (for one batch) at step 70: 1.7545\n",
      "Seen so far: 2272 samples\n",
      "Training loss (for one batch) at step 80: 1.2555\n",
      "Seen so far: 2592 samples\n",
      "Training loss (for one batch) at step 90: 1.4727\n",
      "Seen so far: 2912 samples\n",
      "Training loss (for one batch) at step 100: 1.3415\n",
      "Seen so far: 3232 samples\n",
      "Training loss (for one batch) at step 110: 1.2022\n",
      "Seen so far: 3552 samples\n",
      "Training loss (for one batch) at step 120: 1.1894\n",
      "Seen so far: 3872 samples\n",
      "Training loss (for one batch) at step 130: 1.2399\n",
      "Seen so far: 4192 samples\n",
      "Training loss (for one batch) at step 140: 1.4730\n",
      "Seen so far: 4512 samples\n",
      "Training acc over epoch: 0.4433\n",
      "Training loss over epoch: 1.3345\n",
      "Validation acc: 0.3958\n",
      "Validation loss: 1.4698\n",
      "Time taken: 806.90s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 10: 1.2800\n",
      "Seen so far: 352 samples\n",
      "Training loss (for one batch) at step 20: 1.1286\n",
      "Seen so far: 672 samples\n",
      "Training loss (for one batch) at step 30: 1.3551\n",
      "Seen so far: 992 samples\n",
      "Training loss (for one batch) at step 40: 1.2478\n",
      "Seen so far: 1312 samples\n",
      "Training loss (for one batch) at step 50: 1.1789\n",
      "Seen so far: 1632 samples\n",
      "Training loss (for one batch) at step 60: 1.3440\n",
      "Seen so far: 1952 samples\n",
      "Training loss (for one batch) at step 70: 1.4100\n",
      "Seen so far: 2272 samples\n",
      "Training loss (for one batch) at step 80: 1.1404\n",
      "Seen so far: 2592 samples\n",
      "Training loss (for one batch) at step 90: 1.3839\n",
      "Seen so far: 2912 samples\n",
      "Training loss (for one batch) at step 100: 1.0771\n",
      "Seen so far: 3232 samples\n",
      "Training loss (for one batch) at step 110: 1.2330\n",
      "Seen so far: 3552 samples\n",
      "Training loss (for one batch) at step 120: 1.0280\n",
      "Seen so far: 3872 samples\n",
      "Training loss (for one batch) at step 130: 1.3699\n",
      "Seen so far: 4192 samples\n",
      "Training loss (for one batch) at step 140: 1.1976\n",
      "Seen so far: 4512 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc over epoch: 0.4606\n",
      "Training loss over epoch: 1.2609\n",
      "Validation acc: 0.3908\n",
      "Validation loss: 1.5607\n",
      "Time taken: 830.17s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 10: 1.0288\n",
      "Seen so far: 352 samples\n",
      "Training loss (for one batch) at step 20: 0.9756\n",
      "Seen so far: 672 samples\n",
      "Training loss (for one batch) at step 30: 1.4294\n",
      "Seen so far: 992 samples\n",
      "Training loss (for one batch) at step 40: 1.2580\n",
      "Seen so far: 1312 samples\n",
      "Training loss (for one batch) at step 50: 1.3389\n",
      "Seen so far: 1632 samples\n",
      "Training loss (for one batch) at step 60: 1.2788\n",
      "Seen so far: 1952 samples\n",
      "Training loss (for one batch) at step 70: 1.2834\n",
      "Seen so far: 2272 samples\n",
      "Training loss (for one batch) at step 80: 1.1449\n",
      "Seen so far: 2592 samples\n",
      "Training loss (for one batch) at step 90: 1.3274\n",
      "Seen so far: 2912 samples\n",
      "Training loss (for one batch) at step 100: 1.2115\n",
      "Seen so far: 3232 samples\n",
      "Training loss (for one batch) at step 110: 1.2637\n",
      "Seen so far: 3552 samples\n",
      "Training loss (for one batch) at step 120: 1.1692\n",
      "Seen so far: 3872 samples\n",
      "Training loss (for one batch) at step 130: 1.1593\n",
      "Seen so far: 4192 samples\n",
      "Training loss (for one batch) at step 140: 1.0856\n",
      "Seen so far: 4512 samples\n",
      "Training acc over epoch: 0.4779\n",
      "Training loss over epoch: 1.2379\n",
      "Validation acc: 0.3833\n",
      "Validation loss: 1.5704\n",
      "Time taken: 851.31s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 10: 1.0179\n",
      "Seen so far: 352 samples\n",
      "Training loss (for one batch) at step 20: 1.0749\n",
      "Seen so far: 672 samples\n",
      "Training loss (for one batch) at step 30: 1.2830\n",
      "Seen so far: 992 samples\n",
      "Training loss (for one batch) at step 40: 1.2248\n",
      "Seen so far: 1312 samples\n",
      "Training loss (for one batch) at step 50: 1.1046\n",
      "Seen so far: 1632 samples\n",
      "Training loss (for one batch) at step 60: 1.0569\n",
      "Seen so far: 1952 samples\n",
      "Training loss (for one batch) at step 70: 1.0664\n",
      "Seen so far: 2272 samples\n",
      "Training loss (for one batch) at step 80: 1.1409\n",
      "Seen so far: 2592 samples\n",
      "Training loss (for one batch) at step 90: 1.0955\n",
      "Seen so far: 2912 samples\n",
      "Training loss (for one batch) at step 100: 0.9892\n",
      "Seen so far: 3232 samples\n",
      "Training loss (for one batch) at step 110: 0.8427\n",
      "Seen so far: 3552 samples\n",
      "Training loss (for one batch) at step 120: 1.2009\n",
      "Seen so far: 3872 samples\n",
      "Training loss (for one batch) at step 130: 1.1631\n",
      "Seen so far: 4192 samples\n",
      "Training loss (for one batch) at step 140: 1.2157\n",
      "Seen so far: 4512 samples\n",
      "Training acc over epoch: 0.5150\n",
      "Training loss over epoch: 1.1581\n",
      "Validation acc: 0.3717\n",
      "Validation loss: 1.6250\n",
      "Time taken: 856.97s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 10: 1.3798\n",
      "Seen so far: 352 samples\n",
      "Training loss (for one batch) at step 20: 0.7513\n",
      "Seen so far: 672 samples\n",
      "Training loss (for one batch) at step 30: 1.2418\n",
      "Seen so far: 992 samples\n",
      "Training loss (for one batch) at step 40: 0.9488\n",
      "Seen so far: 1312 samples\n",
      "Training loss (for one batch) at step 50: 1.0336\n",
      "Seen so far: 1632 samples\n",
      "Training loss (for one batch) at step 60: 1.1432\n",
      "Seen so far: 1952 samples\n",
      "Training loss (for one batch) at step 70: 1.1622\n",
      "Seen so far: 2272 samples\n",
      "Training loss (for one batch) at step 80: 1.0454\n",
      "Seen so far: 2592 samples\n",
      "Training loss (for one batch) at step 90: 1.1383\n",
      "Seen so far: 2912 samples\n",
      "Training loss (for one batch) at step 100: 1.0645\n",
      "Seen so far: 3232 samples\n",
      "Training loss (for one batch) at step 110: 1.0058\n",
      "Seen so far: 3552 samples\n",
      "Training loss (for one batch) at step 120: 1.3619\n",
      "Seen so far: 3872 samples\n",
      "Training loss (for one batch) at step 130: 1.0060\n",
      "Seen so far: 4192 samples\n",
      "Training loss (for one batch) at step 140: 1.0881\n",
      "Seen so far: 4512 samples\n",
      "Training acc over epoch: 0.5390\n",
      "Training loss over epoch: 1.0900\n",
      "Validation acc: 0.3792\n",
      "Validation loss: 1.7728\n",
      "Time taken: 852.44s\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at step 10: 0.8452\n",
      "Seen so far: 352 samples\n",
      "Training loss (for one batch) at step 20: 0.8796\n",
      "Seen so far: 672 samples\n",
      "Training loss (for one batch) at step 30: 1.2680\n",
      "Seen so far: 992 samples\n",
      "Training loss (for one batch) at step 40: 0.8630\n",
      "Seen so far: 1312 samples\n",
      "Training loss (for one batch) at step 50: 1.2959\n",
      "Seen so far: 1632 samples\n",
      "Training loss (for one batch) at step 60: 1.0137\n",
      "Seen so far: 1952 samples\n",
      "Training loss (for one batch) at step 70: 0.9664\n",
      "Seen so far: 2272 samples\n",
      "Training loss (for one batch) at step 80: 1.3664\n",
      "Seen so far: 2592 samples\n",
      "Training loss (for one batch) at step 90: 0.9649\n",
      "Seen so far: 2912 samples\n",
      "Training loss (for one batch) at step 100: 1.1975\n",
      "Seen so far: 3232 samples\n",
      "Training loss (for one batch) at step 110: 0.8912\n",
      "Seen so far: 3552 samples\n",
      "Training loss (for one batch) at step 120: 1.1170\n",
      "Seen so far: 3872 samples\n",
      "Training loss (for one batch) at step 130: 1.0543\n",
      "Seen so far: 4192 samples\n",
      "Training loss (for one batch) at step 140: 0.8466\n",
      "Seen so far: 4512 samples\n",
      "Training acc over epoch: 0.5608\n",
      "Training loss over epoch: 1.0360\n",
      "Validation acc: 0.3658\n",
      "Validation loss: 1.9619\n",
      "Time taken: 833.31s\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one batch) at step 10: 1.2605\n",
      "Seen so far: 352 samples\n",
      "Training loss (for one batch) at step 20: 0.7470\n",
      "Seen so far: 672 samples\n",
      "Training loss (for one batch) at step 30: 1.1075\n",
      "Seen so far: 992 samples\n",
      "Training loss (for one batch) at step 40: 0.8765\n",
      "Seen so far: 1312 samples\n",
      "Training loss (for one batch) at step 50: 1.1756\n",
      "Seen so far: 1632 samples\n",
      "Training loss (for one batch) at step 60: 1.1092\n",
      "Seen so far: 1952 samples\n",
      "Training loss (for one batch) at step 70: 0.9576\n",
      "Seen so far: 2272 samples\n",
      "Training loss (for one batch) at step 80: 0.8001\n",
      "Seen so far: 2592 samples\n",
      "Training loss (for one batch) at step 90: 0.7635\n",
      "Seen so far: 2912 samples\n",
      "Training loss (for one batch) at step 100: 1.1237\n",
      "Seen so far: 3232 samples\n",
      "Training loss (for one batch) at step 110: 0.8030\n",
      "Seen so far: 3552 samples\n",
      "Training loss (for one batch) at step 120: 0.9045\n",
      "Seen so far: 3872 samples\n",
      "Training loss (for one batch) at step 130: 1.0697\n",
      "Seen so far: 4192 samples\n",
      "Training loss (for one batch) at step 140: 0.9049\n",
      "Seen so far: 4512 samples\n",
      "Training acc over epoch: 0.5779\n",
      "Training loss over epoch: 0.9916\n",
      "Validation acc: 0.3475\n",
      "Validation loss: 2.0684\n",
      "Time taken: 826.36s\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at step 10: 0.9503\n",
      "Seen so far: 352 samples\n",
      "Training loss (for one batch) at step 20: 0.6812\n",
      "Seen so far: 672 samples\n",
      "Training loss (for one batch) at step 30: 0.8095\n",
      "Seen so far: 992 samples\n",
      "Training loss (for one batch) at step 40: 1.0815\n",
      "Seen so far: 1312 samples\n",
      "Training loss (for one batch) at step 50: 0.7225\n",
      "Seen so far: 1632 samples\n",
      "Training loss (for one batch) at step 60: 0.7644\n",
      "Seen so far: 1952 samples\n",
      "Training loss (for one batch) at step 70: 0.8213\n",
      "Seen so far: 2272 samples\n",
      "Training loss (for one batch) at step 80: 1.0745\n",
      "Seen so far: 2592 samples\n",
      "Training loss (for one batch) at step 90: 0.9223\n",
      "Seen so far: 2912 samples\n",
      "Training loss (for one batch) at step 100: 0.8355\n",
      "Seen so far: 3232 samples\n",
      "Training loss (for one batch) at step 110: 0.8279\n",
      "Seen so far: 3552 samples\n",
      "Training loss (for one batch) at step 120: 0.7841\n",
      "Seen so far: 3872 samples\n",
      "Training loss (for one batch) at step 130: 0.7583\n",
      "Seen so far: 4192 samples\n",
      "Training loss (for one batch) at step 140: 0.9050\n",
      "Seen so far: 4512 samples\n",
      "Training acc over epoch: 0.6112\n",
      "Training loss over epoch: 0.9291\n",
      "Validation acc: 0.3450\n",
      "Validation loss: 2.3257\n",
      "Time taken: 819.07s\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one batch) at step 10: 1.0376\n",
      "Seen so far: 352 samples\n",
      "Training loss (for one batch) at step 20: 0.6586\n",
      "Seen so far: 672 samples\n",
      "Training loss (for one batch) at step 30: 0.8631\n",
      "Seen so far: 992 samples\n",
      "Training loss (for one batch) at step 40: 0.7843\n",
      "Seen so far: 1312 samples\n",
      "Training loss (for one batch) at step 50: 0.8925\n",
      "Seen so far: 1632 samples\n",
      "Training loss (for one batch) at step 60: 1.0605\n",
      "Seen so far: 1952 samples\n",
      "Training loss (for one batch) at step 70: 0.6420\n",
      "Seen so far: 2272 samples\n",
      "Training loss (for one batch) at step 80: 0.8080\n",
      "Seen so far: 2592 samples\n",
      "Training loss (for one batch) at step 90: 0.6437\n",
      "Seen so far: 2912 samples\n",
      "Training loss (for one batch) at step 100: 0.8690\n",
      "Seen so far: 3232 samples\n",
      "Training loss (for one batch) at step 110: 0.9169\n",
      "Seen so far: 3552 samples\n",
      "Training loss (for one batch) at step 120: 1.2473\n",
      "Seen so far: 3872 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 130: 1.0055\n",
      "Seen so far: 4192 samples\n",
      "Training loss (for one batch) at step 140: 0.7535\n",
      "Seen so far: 4512 samples\n",
      "Training acc over epoch: 0.6135\n",
      "Training loss over epoch: 0.9044\n",
      "Validation acc: 0.3433\n",
      "Validation loss: 2.2877\n",
      "Time taken: 794.21s\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at step 10: 0.7975\n",
      "Seen so far: 352 samples\n",
      "Training loss (for one batch) at step 20: 0.7078\n",
      "Seen so far: 672 samples\n",
      "Training loss (for one batch) at step 30: 0.7137\n",
      "Seen so far: 992 samples\n",
      "Training loss (for one batch) at step 40: 0.9078\n",
      "Seen so far: 1312 samples\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(training_batch):\n\u001b[1;32m      8\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m preprocess_input(batch)\n\u001b[0;32m---> 10\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Log every 200 batches.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m step \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Custom Training loop:\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    print(\"\\nStart of epoch %d\" % (epoch))\n",
    "    # Shuffle the training batch for each epoch:\n",
    "    random.shuffle(training_batch)\n",
    "    for step, batch in enumerate(training_batch):\n",
    "        x, y = preprocess_input(batch)\n",
    "        \n",
    "        loss = train_step(x, y)\n",
    "        \n",
    "        # Log every 200 batches.\n",
    "        if step % 10 == 0 and step != 0:\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step, float(loss))\n",
    "            )\n",
    "            print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n",
    "    \n",
    "    # Display metrics at the end of each epoch.\n",
    "    train_acc = train_metrics.result()\n",
    "    print(\"Training acc over epoch: %.4f\" % (float(train_acc)))\n",
    "    loss_train = train_loss.result()\n",
    "    print(\"Training loss over epoch: %.4f\" % (float(loss_train)))\n",
    "    \n",
    "    # Reset training metrics at the end of each epoch\n",
    "    train_metrics.reset_states()\n",
    "    train_loss.reset_states()\n",
    "    \n",
    "    # For validation data:\n",
    "    for val_batch in validation_batch:\n",
    "        x_val, y_val = preprocess_input(val_batch)\n",
    "        \n",
    "        valid_step(x_val, y_val)\n",
    "        \n",
    "\n",
    "    # Metrics\n",
    "    val_acc = validation_metrics.result()\n",
    "    loss_val = validation_loss.result()\n",
    "    validation_metrics.reset_states()\n",
    "    validation_loss.reset_states()\n",
    "    \n",
    "    # Append to a list for graph:\n",
    "    epoch_accuracy_train.append(train_acc)\n",
    "    epoch_accuracy_val.append(val_acc)\n",
    "    epoch_loss_train.append(loss_train)\n",
    "    epoch_loss_val.append(loss_val)\n",
    "    \n",
    "    print(\"Validation acc: %.4f\" % (float(val_acc)))\n",
    "    print(\"Validation loss: %.4f\" % (float(loss_val)))\n",
    "    print(\"Time taken: %.2fs\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bd8c0e",
   "metadata": {},
   "source": [
    "# Plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ace2e8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f9f7e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_x = [i+1 for i in range(epochs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87577487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.scatter(x = axis_x, y = epoch_accuracy_train, label = \"train\")\n",
    "ax.scatter(x = axis_x, y = epoch_accuracy_val, label=\"validation\")\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "ax.set_title(\"Accuracy per epoch\")\n",
    "ax.set_xticks(ticks = axis_x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aeca8d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.scatter(x = axis_x, y = epoch_loss_train, label=\"train\")\n",
    "ax.scatter(x = axis_x, y = epoch_loss_val, label=\"validation\")\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "ax.set_title(\"Loss per epoch\")\n",
    "ax.set_xticks(ticks = axis_x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333c65a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
