{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fafe86bf",
   "metadata": {},
   "source": [
    "# Modelling BIDIRECTIONAL\n",
    "- This notebook uses the data obtained from Pre-Processing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2674903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import librosa\n",
    "import multiprocessing as mp\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52ceb613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Seed for Reproducibility\n",
    "tf.keras.utils.set_random_seed(442)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57c25fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 09:22:36.455734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 09:22:36.463286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 09:22:36.463436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "# GPU Usage\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "# Set memory growth\n",
    "tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44e0892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeldict = {\n",
    "    'Sadness': 0,\n",
    "    'Excited': 1,\n",
    "    'Happiness': 2,\n",
    "    'Anger' : 3,\n",
    "    'Frustration' : 4,\n",
    "    'Other' : 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccf9f9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(label):\n",
    "    one_hot = np.zeros(6)\n",
    "    one_hot[labeldict[label]] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d30a007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_list(listOfLabels):\n",
    "    finalList = []\n",
    "    for label in listOfLabels:\n",
    "        finalList.append(one_hot_encode(label))\n",
    "    return np.array(finalList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "904a4ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mel_and_label(path):\n",
    "    emotion = re.match('.*/DATA/([a-zA-Z]+)/.*', path).groups()[0]\n",
    "    data, _ = librosa.load(path, sr=44100)\n",
    "    mels = librosa.feature.melspectrogram(y=data, sr=44100, n_mels=256)\n",
    "    return mels, emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "822e9899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(pathList): # Returns a list of x (batch_size, timesteps, feature), y (one_hot_encoded)\n",
    "    with mp.Pool() as p:\n",
    "        results = p.map(get_mel_and_label, pathList)\n",
    "    # Preprocess x:\n",
    "    x = [item[0] for item in results]\n",
    "    # Flatten\n",
    "    x = [item for sublist in x for item in sublist]\n",
    "    # Zero-padding:\n",
    "    x = keras.preprocessing.sequence.pad_sequences(x, padding=\"post\", maxlen=1497, dtype = np.float16) # maxlen is after discovering the whole training data\n",
    "    # Reshaping so that the order is not messed up\n",
    "    x = x.reshape(-1, 256, 1497)\n",
    "    # Transposing so that we have timesteps in dim 1\n",
    "    x = x.transpose((0, 2, 1))\n",
    "    # Convert to tensor and of type tf.float16 for faster operation\n",
    "    x = tf.convert_to_tensor(x, dtype=tf.float16)\n",
    "    # Preprocess y:\n",
    "    y = [item[1] for item in results]\n",
    "    # one_hot_encode\n",
    "    y = one_hot_encode_list(y)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8a5000",
   "metadata": {},
   "source": [
    "# Loading data: \n",
    "- We will load the data per predefined batch size, this is to reduce the memory used for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5fbf7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_paths.pkl', 'rb') as f:\n",
    "    train_paths = pickle.load(f)\n",
    "with open('test_paths.pkl', 'rb') as f:\n",
    "    test_paths = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "841dfc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make batches of the pathList:\n",
    "def create_batches(pathList, batch_size):\n",
    "    ansList = [] # To store the final batched paths\n",
    "    tempList = [] # Temporary list\n",
    "    count = 0\n",
    "    while count < len(pathList):\n",
    "        tempList.append(pathList[count]) # Append the path\n",
    "        count += 1\n",
    "        if (count % batch_size) == 0: # if count is a multiple of batch_size\n",
    "            ansList.append(tempList)\n",
    "            tempList = []\n",
    "    if len(tempList) != 0: # If tempList is not empty\n",
    "        ansList.append(tempList) # Append the remaining values\n",
    "    return ansList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28921b58",
   "metadata": {},
   "source": [
    "# Modelling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "920ba4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 09:22:38.146658: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 09:22:38.147357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 09:22:38.147526: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 09:22:38.147627: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 09:22:38.454612: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 09:22:38.454737: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 09:22:38.454803: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 09:22:38.454866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6108 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Keras API:\n",
    "inp = layers.Input(shape=(1497, 256)) # Let's make to fixed so that we could use CNN more efficiently\n",
    "# LSTM:\n",
    "x_LSTM = layers.Masking(mask_value=0.0)(inp)\n",
    "x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.3))(x_LSTM)\n",
    "x = layers.Bidirectional(layers.LSTM(128, dropout=0.3, recurrent_dropout=0.3))(x)\n",
    "\n",
    "\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "x = layers.Dense(6, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inp, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3908fe4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1497, 256)]       0         \n",
      "                                                                 \n",
      " masking (Masking)           (None, 1497, 256)         0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 1497, 256)        394240    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 256)              394240    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 830,022\n",
      "Trainable params: 830,022\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b122fa",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28347024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch_size is 32, epochs = 30\n",
    "batch_size = 32\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87f92c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer is Stochastic Gradient Descent\n",
    "# Loss function is Categorical Crossentropy\n",
    "optimizer = keras.optimizers.Adam() #amsgrad=True\n",
    "loss_fn = keras.losses.CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc25bc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_batch = create_batches(train_paths, batch_size=batch_size)\n",
    "validation_batch = create_batches(test_paths, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3369e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics:\n",
    "train_metrics = tf.keras.metrics.CategoricalAccuracy()\n",
    "validation_metrics = tf.keras.metrics.CategoricalAccuracy()\n",
    "train_loss = tf.keras.metrics.CategoricalCrossentropy()\n",
    "validation_loss = tf.keras.metrics.CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "538ba3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list to store epoch results:\n",
    "epoch_accuracy_train = []\n",
    "epoch_accuracy_val = []\n",
    "epoch_loss_train = []\n",
    "epoch_loss_val = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f3c97fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To speed up, use graph execution\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x, training = True)\n",
    "        loss = loss_fn(y, y_pred)\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    # Update training accuracy\n",
    "    train_metrics.update_state(y, y_pred)\n",
    "    # Update training loss:\n",
    "    train_loss.update_state(y, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a850e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def valid_step(x, y):\n",
    "    y_val_pred = model(x, training=False)\n",
    "    # Update metrics for validation\n",
    "    validation_metrics.update_state(y, y_val_pred)\n",
    "    validation_loss.update_state(y, y_val_pred)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1971ed86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 09:23:09.082392: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 10: 1.8447\n",
      "Seen so far: 352 samples\n",
      "Training loss (for one batch) at step 20: 1.7773\n",
      "Seen so far: 672 samples\n",
      "Training loss (for one batch) at step 30: 1.7794\n",
      "Seen so far: 992 samples\n",
      "Training loss (for one batch) at step 40: 1.8115\n",
      "Seen so far: 1312 samples\n",
      "Training loss (for one batch) at step 50: 1.7058\n",
      "Seen so far: 1632 samples\n",
      "Training loss (for one batch) at step 60: 1.6689\n",
      "Seen so far: 1952 samples\n",
      "Training loss (for one batch) at step 70: 1.6915\n",
      "Seen so far: 2272 samples\n",
      "Training loss (for one batch) at step 80: 1.8661\n",
      "Seen so far: 2592 samples\n",
      "Training loss (for one batch) at step 90: 1.7245\n",
      "Seen so far: 2912 samples\n",
      "Training loss (for one batch) at step 100: 1.8284\n",
      "Seen so far: 3232 samples\n",
      "Training loss (for one batch) at step 110: 1.8030\n",
      "Seen so far: 3552 samples\n",
      "Training loss (for one batch) at step 120: 1.8616\n",
      "Seen so far: 3872 samples\n",
      "Training loss (for one batch) at step 130: 1.6382\n",
      "Seen so far: 4192 samples\n",
      "Training loss (for one batch) at step 140: 1.8395\n",
      "Seen so far: 4512 samples\n",
      "Training acc over epoch: 0.2067\n",
      "Training loss over epoch: 1.7602\n",
      "Validation acc: 0.2542\n",
      "Validation loss: 1.6984\n",
      "Time taken: 1210.63s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 10: 1.7955\n",
      "Seen so far: 352 samples\n",
      "Training loss (for one batch) at step 20: 1.5908\n",
      "Seen so far: 672 samples\n",
      "Training loss (for one batch) at step 30: 1.7183\n",
      "Seen so far: 992 samples\n",
      "Training loss (for one batch) at step 40: 1.7386\n",
      "Seen so far: 1312 samples\n",
      "Training loss (for one batch) at step 50: 1.7744\n",
      "Seen so far: 1632 samples\n",
      "Training loss (for one batch) at step 60: 1.8384\n",
      "Seen so far: 1952 samples\n",
      "Training loss (for one batch) at step 70: 1.6473\n",
      "Seen so far: 2272 samples\n",
      "Training loss (for one batch) at step 80: 1.6914\n",
      "Seen so far: 2592 samples\n",
      "Training loss (for one batch) at step 90: 1.7101\n",
      "Seen so far: 2912 samples\n",
      "Training loss (for one batch) at step 100: 1.7940\n",
      "Seen so far: 3232 samples\n",
      "Training loss (for one batch) at step 110: 1.7374\n",
      "Seen so far: 3552 samples\n",
      "Training loss (for one batch) at step 120: 1.6921\n",
      "Seen so far: 3872 samples\n",
      "Training loss (for one batch) at step 130: 1.6358\n",
      "Seen so far: 4192 samples\n",
      "Training loss (for one batch) at step 140: 1.8955\n",
      "Seen so far: 4512 samples\n",
      "Training acc over epoch: 0.2346\n",
      "Training loss over epoch: 1.7298\n",
      "Validation acc: 0.2167\n",
      "Validation loss: 1.7393\n",
      "Time taken: 1171.63s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 10: 2.0553\n",
      "Seen so far: 352 samples\n",
      "Training loss (for one batch) at step 20: 1.8216\n",
      "Seen so far: 672 samples\n",
      "Training loss (for one batch) at step 30: 1.6696\n",
      "Seen so far: 992 samples\n",
      "Training loss (for one batch) at step 40: 1.6558\n",
      "Seen so far: 1312 samples\n",
      "Training loss (for one batch) at step 50: 1.7853\n",
      "Seen so far: 1632 samples\n",
      "Training loss (for one batch) at step 60: 1.7498\n",
      "Seen so far: 1952 samples\n",
      "Training loss (for one batch) at step 70: 1.7572\n",
      "Seen so far: 2272 samples\n",
      "Training loss (for one batch) at step 80: 1.6992\n",
      "Seen so far: 2592 samples\n",
      "Training loss (for one batch) at step 90: 1.7321\n",
      "Seen so far: 2912 samples\n",
      "Training loss (for one batch) at step 100: 1.7813\n",
      "Seen so far: 3232 samples\n",
      "Training loss (for one batch) at step 110: 1.7258\n",
      "Seen so far: 3552 samples\n",
      "Training loss (for one batch) at step 120: 1.6707\n",
      "Seen so far: 3872 samples\n",
      "Training loss (for one batch) at step 130: 1.7669\n",
      "Seen so far: 4192 samples\n",
      "Training loss (for one batch) at step 140: 1.7066\n",
      "Seen so far: 4512 samples\n",
      "Training acc over epoch: 0.2327\n",
      "Training loss over epoch: 1.7396\n",
      "Validation acc: 0.2417\n",
      "Validation loss: 1.7750\n",
      "Time taken: 1182.44s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 10: 1.7060\n",
      "Seen so far: 352 samples\n",
      "Training loss (for one batch) at step 20: 1.7297\n",
      "Seen so far: 672 samples\n",
      "Training loss (for one batch) at step 30: 1.8366\n",
      "Seen so far: 992 samples\n",
      "Training loss (for one batch) at step 40: 1.7049\n",
      "Seen so far: 1312 samples\n",
      "Training loss (for one batch) at step 50: 1.7999\n",
      "Seen so far: 1632 samples\n",
      "Training loss (for one batch) at step 60: 1.7540\n",
      "Seen so far: 1952 samples\n",
      "Training loss (for one batch) at step 70: 1.7520\n",
      "Seen so far: 2272 samples\n",
      "Training loss (for one batch) at step 80: 1.6226\n",
      "Seen so far: 2592 samples\n",
      "Training loss (for one batch) at step 90: 1.7303\n",
      "Seen so far: 2912 samples\n",
      "Training loss (for one batch) at step 100: 1.6789\n",
      "Seen so far: 3232 samples\n",
      "Training loss (for one batch) at step 110: 1.7885\n",
      "Seen so far: 3552 samples\n",
      "Training loss (for one batch) at step 120: 1.7751\n",
      "Seen so far: 3872 samples\n",
      "Training loss (for one batch) at step 130: 1.6101\n",
      "Seen so far: 4192 samples\n",
      "Training loss (for one batch) at step 140: 1.7843\n",
      "Seen so far: 4512 samples\n",
      "Training acc over epoch: 0.2385\n",
      "Training loss over epoch: 1.7309\n",
      "Validation acc: 0.2725\n",
      "Validation loss: 1.6743\n",
      "Time taken: 1200.61s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 10: 1.7417\n",
      "Seen so far: 352 samples\n",
      "Training loss (for one batch) at step 20: 1.6470\n",
      "Seen so far: 672 samples\n",
      "Training loss (for one batch) at step 30: 1.6138\n",
      "Seen so far: 992 samples\n",
      "Training loss (for one batch) at step 40: 1.7115\n",
      "Seen so far: 1312 samples\n",
      "Training loss (for one batch) at step 50: 1.7252\n",
      "Seen so far: 1632 samples\n",
      "Training loss (for one batch) at step 60: 1.7732\n",
      "Seen so far: 1952 samples\n",
      "Training loss (for one batch) at step 70: 1.6555\n",
      "Seen so far: 2272 samples\n",
      "Training loss (for one batch) at step 80: 1.8325\n",
      "Seen so far: 2592 samples\n",
      "Training loss (for one batch) at step 90: 1.6161\n",
      "Seen so far: 2912 samples\n",
      "Training loss (for one batch) at step 100: 1.7254\n",
      "Seen so far: 3232 samples\n",
      "Training loss (for one batch) at step 110: 1.7092\n",
      "Seen so far: 3552 samples\n",
      "Training loss (for one batch) at step 120: 1.7287\n",
      "Seen so far: 3872 samples\n",
      "Training loss (for one batch) at step 130: 1.6727\n",
      "Seen so far: 4192 samples\n",
      "Training loss (for one batch) at step 140: 1.5870\n",
      "Seen so far: 4512 samples\n",
      "Training acc over epoch: 0.2567\n",
      "Training loss over epoch: 1.6784\n",
      "Validation acc: 0.2825\n",
      "Validation loss: 1.6727\n",
      "Time taken: 1145.97s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 10: 1.5982\n",
      "Seen so far: 352 samples\n",
      "Training loss (for one batch) at step 20: 1.6033\n",
      "Seen so far: 672 samples\n",
      "Training loss (for one batch) at step 30: 1.5452\n",
      "Seen so far: 992 samples\n",
      "Training loss (for one batch) at step 40: 1.6047\n",
      "Seen so far: 1312 samples\n",
      "Training loss (for one batch) at step 50: 1.6276\n",
      "Seen so far: 1632 samples\n",
      "Training loss (for one batch) at step 60: 1.6669\n",
      "Seen so far: 1952 samples\n",
      "Training loss (for one batch) at step 70: 1.7999\n",
      "Seen so far: 2272 samples\n",
      "Training loss (for one batch) at step 80: 1.7765\n",
      "Seen so far: 2592 samples\n",
      "Training loss (for one batch) at step 90: 1.5952\n",
      "Seen so far: 2912 samples\n",
      "Training loss (for one batch) at step 100: 1.6303\n",
      "Seen so far: 3232 samples\n",
      "Training loss (for one batch) at step 110: 1.6888\n",
      "Seen so far: 3552 samples\n",
      "Training loss (for one batch) at step 120: 1.7297\n",
      "Seen so far: 3872 samples\n",
      "Training loss (for one batch) at step 130: 1.6945\n",
      "Seen so far: 4192 samples\n",
      "Training loss (for one batch) at step 140: 1.6625\n",
      "Seen so far: 4512 samples\n",
      "Training acc over epoch: 0.2798\n",
      "Training loss over epoch: 1.6763\n",
      "Validation acc: 0.2758\n",
      "Validation loss: 1.6642\n",
      "Time taken: 1117.01s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 10: 1.6762\n",
      "Seen so far: 352 samples\n",
      "Training loss (for one batch) at step 20: 1.7065\n",
      "Seen so far: 672 samples\n",
      "Training loss (for one batch) at step 30: 1.6535\n",
      "Seen so far: 992 samples\n",
      "Training loss (for one batch) at step 40: 1.6760\n",
      "Seen so far: 1312 samples\n",
      "Training loss (for one batch) at step 50: 1.7181\n",
      "Seen so far: 1632 samples\n",
      "Training loss (for one batch) at step 60: 1.6255\n",
      "Seen so far: 1952 samples\n",
      "Training loss (for one batch) at step 70: 1.7065\n",
      "Seen so far: 2272 samples\n",
      "Training loss (for one batch) at step 80: 1.7262\n",
      "Seen so far: 2592 samples\n",
      "Training loss (for one batch) at step 90: 1.7520\n",
      "Seen so far: 2912 samples\n",
      "Training loss (for one batch) at step 100: 1.6181\n",
      "Seen so far: 3232 samples\n",
      "Training loss (for one batch) at step 110: 1.6118\n",
      "Seen so far: 3552 samples\n",
      "Training loss (for one batch) at step 120: 1.6829\n",
      "Seen so far: 3872 samples\n",
      "Training loss (for one batch) at step 130: 1.6404\n",
      "Seen so far: 4192 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 140: 1.6914\n",
      "Seen so far: 4512 samples\n",
      "Training acc over epoch: 0.2788\n",
      "Training loss over epoch: 1.6750\n",
      "Validation acc: 0.3000\n",
      "Validation loss: 1.6766\n",
      "Time taken: 1192.69s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 10: 1.6479\n",
      "Seen so far: 352 samples\n",
      "Training loss (for one batch) at step 20: 1.6165\n",
      "Seen so far: 672 samples\n",
      "Training loss (for one batch) at step 30: 1.8046\n",
      "Seen so far: 992 samples\n",
      "Training loss (for one batch) at step 40: 1.8073\n",
      "Seen so far: 1312 samples\n",
      "Training loss (for one batch) at step 50: 1.7251\n",
      "Seen so far: 1632 samples\n",
      "Training loss (for one batch) at step 60: 1.5799\n",
      "Seen so far: 1952 samples\n",
      "Training loss (for one batch) at step 70: 1.7265\n",
      "Seen so far: 2272 samples\n",
      "Training loss (for one batch) at step 80: 1.5802\n",
      "Seen so far: 2592 samples\n",
      "Training loss (for one batch) at step 90: 1.5731\n",
      "Seen so far: 2912 samples\n",
      "Training loss (for one batch) at step 100: 1.6574\n",
      "Seen so far: 3232 samples\n",
      "Training loss (for one batch) at step 110: 1.7410\n",
      "Seen so far: 3552 samples\n",
      "Training loss (for one batch) at step 120: 1.7024\n",
      "Seen so far: 3872 samples\n",
      "Training loss (for one batch) at step 130: 1.7586\n",
      "Seen so far: 4192 samples\n",
      "Training loss (for one batch) at step 140: 1.5583\n",
      "Seen so far: 4512 samples\n",
      "Training acc over epoch: 0.2779\n",
      "Training loss over epoch: 1.6565\n",
      "Validation acc: 0.3000\n",
      "Validation loss: 1.6465\n",
      "Time taken: 1186.81s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 10: 1.6299\n",
      "Seen so far: 352 samples\n",
      "Training loss (for one batch) at step 20: 1.6515\n",
      "Seen so far: 672 samples\n",
      "Training loss (for one batch) at step 30: 1.6567\n",
      "Seen so far: 992 samples\n",
      "Training loss (for one batch) at step 40: 1.6719\n",
      "Seen so far: 1312 samples\n",
      "Training loss (for one batch) at step 50: 1.6854\n",
      "Seen so far: 1632 samples\n",
      "Training loss (for one batch) at step 60: 1.5250\n",
      "Seen so far: 1952 samples\n",
      "Training loss (for one batch) at step 70: 1.6768\n",
      "Seen so far: 2272 samples\n",
      "Training loss (for one batch) at step 80: 1.6319\n",
      "Seen so far: 2592 samples\n",
      "Training loss (for one batch) at step 90: 1.6756\n",
      "Seen so far: 2912 samples\n",
      "Training loss (for one batch) at step 100: 1.6102\n",
      "Seen so far: 3232 samples\n",
      "Training loss (for one batch) at step 110: 1.7187\n",
      "Seen so far: 3552 samples\n",
      "Training loss (for one batch) at step 120: 1.5325\n",
      "Seen so far: 3872 samples\n",
      "Training loss (for one batch) at step 130: 1.6789\n",
      "Seen so far: 4192 samples\n",
      "Training loss (for one batch) at step 140: 1.6932\n",
      "Seen so far: 4512 samples\n",
      "Training acc over epoch: 0.2846\n",
      "Training loss over epoch: 1.6553\n",
      "Validation acc: 0.3008\n",
      "Validation loss: 1.6517\n",
      "Time taken: 1166.14s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 10: 1.6372\n",
      "Seen so far: 352 samples\n",
      "Training loss (for one batch) at step 20: 1.3840\n",
      "Seen so far: 672 samples\n",
      "Training loss (for one batch) at step 30: 1.5956\n",
      "Seen so far: 992 samples\n",
      "Training loss (for one batch) at step 40: 1.6526\n",
      "Seen so far: 1312 samples\n",
      "Training loss (for one batch) at step 50: 1.5892\n",
      "Seen so far: 1632 samples\n",
      "Training loss (for one batch) at step 60: 1.6457\n",
      "Seen so far: 1952 samples\n",
      "Training loss (for one batch) at step 70: 1.6517\n",
      "Seen so far: 2272 samples\n",
      "Training loss (for one batch) at step 80: 1.6839\n",
      "Seen so far: 2592 samples\n",
      "Training loss (for one batch) at step 90: 1.7149\n",
      "Seen so far: 2912 samples\n",
      "Training loss (for one batch) at step 100: 1.7175\n",
      "Seen so far: 3232 samples\n",
      "Training loss (for one batch) at step 110: 1.7716\n",
      "Seen so far: 3552 samples\n",
      "Training loss (for one batch) at step 120: 1.6347\n",
      "Seen so far: 3872 samples\n",
      "Training loss (for one batch) at step 130: 1.5054\n",
      "Seen so far: 4192 samples\n",
      "Training loss (for one batch) at step 140: 1.4914\n",
      "Seen so far: 4512 samples\n",
      "Training acc over epoch: 0.2981\n",
      "Training loss over epoch: 1.6432\n",
      "Validation acc: 0.2850\n",
      "Validation loss: 1.6378\n",
      "Time taken: 1147.34s\n"
     ]
    }
   ],
   "source": [
    "# Custom Training loop:\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    print(\"\\nStart of epoch %d\" % (epoch))\n",
    "    # Shuffle the training batch for each epoch:\n",
    "    random.shuffle(training_batch)\n",
    "    for step, batch in enumerate(training_batch):\n",
    "        x, y = preprocess_input(batch)\n",
    "        \n",
    "        loss = train_step(x, y)\n",
    "        \n",
    "        # Log every 200 batches.\n",
    "        if step % 10 == 0 and step != 0:\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step, float(loss))\n",
    "            )\n",
    "            print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n",
    "    \n",
    "    # Display metrics at the end of each epoch.\n",
    "    train_acc = train_metrics.result()\n",
    "    print(\"Training acc over epoch: %.4f\" % (float(train_acc)))\n",
    "    loss_train = train_loss.result()\n",
    "    print(\"Training loss over epoch: %.4f\" % (float(loss_train)))\n",
    "    \n",
    "    # Reset training metrics at the end of each epoch\n",
    "    train_metrics.reset_states()\n",
    "    train_loss.reset_states()\n",
    "    \n",
    "    # For validation data:\n",
    "    for val_batch in validation_batch:\n",
    "        x_val, y_val = preprocess_input(val_batch)\n",
    "        \n",
    "        valid_step(x_val, y_val)\n",
    "        \n",
    "\n",
    "    # Metrics\n",
    "    val_acc = validation_metrics.result()\n",
    "    loss_val = validation_loss.result()\n",
    "    validation_metrics.reset_states()\n",
    "    validation_loss.reset_states()\n",
    "    \n",
    "    # Append to a list for graph:\n",
    "    epoch_accuracy_train.append(train_acc)\n",
    "    epoch_accuracy_val.append(val_acc)\n",
    "    epoch_loss_train.append(loss_train)\n",
    "    epoch_loss_val.append(loss_val)\n",
    "    \n",
    "    print(\"Validation acc: %.4f\" % (float(val_acc)))\n",
    "    print(\"Validation loss: %.4f\" % (float(loss_val)))\n",
    "    print(\"Time taken: %.2fs\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "930217b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"MEL_BI.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bd8c0e",
   "metadata": {},
   "source": [
    "# Plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ace2e8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f9f7e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_x = [i+1 for i in range(epochs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87577487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.scatter(x = axis_x, y = epoch_accuracy_train, label = \"train\")\n",
    "ax.scatter(x = axis_x, y = epoch_accuracy_val, label=\"validation\")\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "ax.set_title(\"Accuracy per epoch\")\n",
    "ax.set_xticks(ticks = axis_x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aeca8d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.scatter(x = axis_x, y = epoch_loss_train, label=\"train\")\n",
    "ax.scatter(x = axis_x, y = epoch_loss_val, label=\"validation\")\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "ax.set_title(\"Loss per epoch\")\n",
    "ax.set_xticks(ticks = axis_x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333c65a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
